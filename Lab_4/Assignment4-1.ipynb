{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sTsDfIVKsmL"
   },
   "source": [
    "# DAT405 Introduction to Data Science and AI \n",
    "## 2022-2023, Reading Period 3\n",
    "## Assignment 4: Spam classification using Naïve Bayes \n",
    "This assignmetn has three obligatory questions which will be grades as PASS/FAIL. Questions 4-5 are optional and will not be graded, but can be interesting for students aiming for higher grades.\n",
    "\n",
    "The exercise takes place in this notebook environment where you can chose to use Jupyter or Google Colabs. We recommend you use Google Colabs as it will facilitate remote group-work and makes the assignment less technical. \n",
    "Hints:\n",
    "You can execute certain linux shell commands by prefixing the command with `!`. You can insert Markdown cells and code cells. The first you can use for documenting and explaining your results the second you can use writing code snippets that execute the tasks required.  \n",
    "\n",
    "In this assignment you will implement a Naïve Bayes classifier in Python that will classify emails into spam and non-spam (“ham”) classes.  Your program should be able to train on a given set of spam and “ham” datasets. \n",
    "You will work with the datasets available at https://spamassassin.apache.org/old/publiccorpus/. There are three types of files in this location: \n",
    "-\teasy-ham: non-spam messages typically quite easy to differentiate from spam messages. \n",
    "-\thard-ham: non-spam messages more difficult to differentiate \n",
    "-\tspam: spam messages \n",
    "\n",
    "**Execute the cell below to download and extract the data into the environment of the notebook -- it will take a few seconds.** If you chose to use Jupyter notebooks you will have to run the commands in the cell below on your local computer, with Windows you can use \n",
    "7zip (https://www.7-zip.org/download.html) to decompress the data.\n",
    "\n",
    "**What to submit:** \n",
    "Convert the notebook to a pdf-file and submit it. Make sure all cells are executed so all your code and its results are included. Double check the pdf displays correctly before you submit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Wa37fBwRF-xe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "tar: Error opening archive: Failed to open '20021010_easy_ham.tar.bz2'\n",
      "tar: Error opening archive: Failed to open '20021010_hard_ham.tar.bz2'\n",
      "tar: Error opening archive: Failed to open '20021010_spam.tar.bz2'\n"
     ]
    }
   ],
   "source": [
    "#Download and extract data\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
    "!tar -xjf 20021010_easy_ham.tar.bz2\n",
    "!tar -xjf 20021010_hard_ham.tar.bz2\n",
    "!tar -xjf 20021010_spam.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdH1XTepLjZ3"
   },
   "source": [
    "*The* data is now in the three folders `easy_ham`, `hard_ham`, and `spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "A53Gw00fBLG2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGlWPVnSNzT7"
   },
   "source": [
    "### 1. Preprocessing: \n",
    "Note that the email files contain a lot of extra information, besides the actual message. Ignore that for now and run on the entire text (in the optional part further down can experiment with filtering out the headers and footers). \n",
    "1.\tWe don’t want to train and test on the same data (it might help to reflect on why if you don't recall). Split the spam and the ham datasets in a training set and a test set. (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`). Use easy_ham for quesions 1 and 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "J2sllUWXKblD"
   },
   "outputs": [],
   "source": [
    "# Write your pre-processing code here\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn.model_selection as skm\n",
    "\n",
    "# Read data from folder and sort it into a dataframe\n",
    "def readData(folder):\n",
    "    files = os.listdir(folder) # 'easy_ham'\n",
    "    df = pd.DataFrame(columns=['file_name', 'data'])\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        with open(folder + '/' + file, 'r', encoding=\"latin-1\") as f:\n",
    "            temp_df = pd.DataFrame({'file_name': file, 'data': f.read()}, index=[i])\n",
    "            df = pd.concat([df, temp_df])\n",
    "    return df\n",
    "\n",
    "# Read data\n",
    "spam = readData('spam')\n",
    "ham = readData('easy_ham')\n",
    "\n",
    "# Create X and y\n",
    "spam_X = spam['data']\n",
    "spam_y = spam['file_name']\n",
    "\n",
    "ham_X = ham['data']\n",
    "ham_y = ham['file_name']\n",
    "\n",
    "# Split data into training and testing\n",
    "s_X_train, s_X_test, s_y_train, s_y_test = skm.train_test_split(spam_X, spam_y, test_size=0.5)\n",
    "h_X_train, h_X_test, h_y_train, h_y_test = skm.train_test_split(ham_X, ham_y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnbrbI0_OKCF"
   },
   "source": [
    "### 2. Write a Python program that: \n",
    "1.\tUses the four datasets from Qustion 1 (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`) \n",
    "2.\tTrains a Naïve Bayes classifier (use the [scikit-learn library](https://scikit-learn.org/stable/)) on `hamtrain` and `spamtrain`, that classifies the test sets and reports True Positive and False Negative rates on the `hamtest` and `spamtest` datasets. You can use `CountVectorizer` ([Documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)) to transform the email texts into vectors. Please note that there are different types of Naïve Bayes Classifier in scikit-learn ([Documentation here](https://scikit-learn.org/stable/modules/naive_bayes.html)). Test two of these classifiers that are well suited for this problem:\n",
    "- Multinomial Naive Bayes  \n",
    "- Bernoulli Naive Bayes. \n",
    "\n",
    "Please inspect the documentation to ensure input to the classifiers is appropriate before you start coding. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "MJERHSCcGNaW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n",
      "256\n",
      "1249\n",
      "1302\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 31025 features, but MultinomialNB is expecting 26243 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m h_model_Multi \u001b[39m=\u001b[39m MultinomialNB()\u001b[39m.\u001b[39mfit(h_X_train_counts, h_y_train)\n\u001b[0;32m     33\u001b[0m \u001b[39m# Predict the testing data\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m s_y_pred_Multi \u001b[39m=\u001b[39m s_model_Multi\u001b[39m.\u001b[39;49mpredict(s_X_test_counts)\n\u001b[0;32m     35\u001b[0m h_y_pred_Multi \u001b[39m=\u001b[39m s_model_Multi\u001b[39m.\u001b[39mpredict(h_X_test_counts)\n\u001b[0;32m     37\u001b[0m \u001b[39m# ---------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[39m# Fit the training data\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\naive_bayes.py:105\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m    Predicted target values for X.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X(X)\n\u001b[0;32m    106\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_joint_log_likelihood(X)\n\u001b[0;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\naive_bayes.py:579\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_X\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    578\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:569\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 569\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    571\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:370\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 370\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 31025 features, but MultinomialNB is expecting 26243 features as input."
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "count_vect = CountVectorizer(analyzer=\"word\")\n",
    "\n",
    "# Fit and transform the training data\n",
    "s_X_train_counts = count_vect.fit_transform(s_X_train)\n",
    "h_X_train_counts = count_vect.fit_transform(h_X_train)\n",
    "\n",
    "# Fit and transform the testing data\n",
    "s_X_test_counts = count_vect.transform(s_X_test)\n",
    "h_X_test_counts = count_vect.transform(h_X_test)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "print(len(s_X_train_counts.toarray()))\n",
    "print(len(s_X_test_counts.toarray()))\n",
    "print(len(h_X_train_counts.toarray()))\n",
    "print(len(h_X_test_counts.toarray()))\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Fit the training data\n",
    "s_model_Multi = MultinomialNB().fit(s_X_train_counts, s_y_train)\n",
    "h_model_Multi = MultinomialNB().fit(h_X_train_counts, h_y_train)\n",
    "\n",
    "# Predict the testing data\n",
    "s_y_pred_Multi = s_model_Multi.predict(s_X_test_counts)\n",
    "h_y_pred_Multi = s_model_Multi.predict(h_X_test_counts)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Fit the training data\n",
    "s_model_Bern = BernoulliNB().fit(s_X_train_counts, s_y_train)\n",
    "h_model_Bern = BernoulliNB().fit(h_X_train_counts, h_y_train)\n",
    "\n",
    "# Predict the testing data\n",
    "s_y_pred_Bern = s_model_Bern.predict(s_X_test_counts)\n",
    "h_y_pred_Bern = s_model_Bern.predict(h_X_test_counts)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Compute the accuracy of the two models\n",
    "print(\"Multinomial\")\n",
    "print(\"Spam Accuracy: \", accuracy_score(s_y_test, s_y_pred_Multi))\n",
    "print(\"Ham Accuracy: \", accuracy_score(h_y_test, h_y_pred_Multi))\n",
    "\n",
    "print(\"-\"*25)\n",
    "\n",
    "print(\"Bernoulli\")\n",
    "print(\"Spam Accuracy: \", accuracy_score(s_y_test, s_y_pred_Bern))\n",
    "print(\"Ham Accuracy: \", accuracy_score(h_y_test, h_y_pred_Bern))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDFS3uFFUcS7"
   },
   "source": [
    "### 3.Run on hard ham:\n",
    "Run the two models from Question 2 on spam versus hard-ham and compare to easy-ham results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gool_zb8Qzzy"
   },
   "outputs": [],
   "source": [
    "#Code to report results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkfQWBB4UhYd"
   },
   "source": [
    "### 4.\tOPTIONAL - NOT MARKED: \n",
    "To avoid classification based on common and uninformative words it is common to filter these out. \n",
    "\n",
    "**a.** Think about why this may be useful. Show a few examples of too common and too uncommon words. \n",
    "\n",
    "**b.** Use the parameters in scikit-learn’s `CountVectorizer` to filter out these words. Update the program from point 2 and run it on easy ham vs spam and hard ham vs spam and report your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qt7ELzEqUfas"
   },
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcyVfOZFU4F_"
   },
   "source": [
    "### 5. OPTIONAL - NOT MARKED: Eeking out further performance\n",
    "Filter out the headers and footers of the emails before you run on them. The format may vary somewhat between emails, which can make this a bit tricky, so perfect filtering is not required. Run your program again and answer the following questions: \n",
    "- Does the result improve from 3 and 4? \n",
    "- What do you expect would happen if your training set were mostly spam messages while your test set were mostly ham messages or vice versa? \n",
    "- Look at the `fit_prior` parameter. What does this parameter mean? Discuss in what settings it can be helpful (you can also test your hypothesis). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkIB6h9k4r07"
   },
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "328c0fc18878b7fc39e649c75fecaa51c14850ce2dacfa42f9248d15be50710f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
